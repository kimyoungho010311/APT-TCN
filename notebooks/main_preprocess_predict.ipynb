{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da4a843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.12.0\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# PART 0: 라이브러리 임포트\n",
    "# ===================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tcn import TCN\n",
    "\n",
    "# 한글 폰트 설정\n",
    "try:\n",
    "    plt.rc('font', family='AppleGothic')\n",
    "except:\n",
    "    plt.rc('font', family='Malgun Gothic')\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "print(f\"TensorFlow Version: {tf.__version__}\")\n",
    "\n",
    "# ===================================================================\n",
    "# PART 1: 경로 및 하이퍼파라미터 설정\n",
    "# ===================================================================\n",
    "# --- 입력 데이터 경로 ---\n",
    "IMAGE_DIRECTORY = '../data/interim/satellites'\n",
    "TABULAR_DATA_PATH = '../data/interim/gang_nam_sendimental_score_with_sale.csv'\n",
    "\n",
    "# --- 모델 하이퍼파라미터 ---\n",
    "TIMESTEPS = 12\n",
    "IMAGE_PCA_COMPONENTS = 32\n",
    "TABULAR_MLP_COMPONENTS = 64\n",
    "FUSION_COMPONENTS = 256\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 50\n",
    "FORECAST_HORIZON = 12\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "433ffd28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PART 2: 데이터 로딩 및 분할 시작...\n",
      "데이터 분할 완료: Train=15092, Validation=4312, Test=2157\n",
      "PART 2: 완료!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ===================================================================\n",
    "# PART 2: 데이터 로딩 및 분할\n",
    "# 모든 전처리 이전에 데이터를 시간순으로 분할하여 데이터 유출(Data Leakage)을 방지합니다.\n",
    "# ===================================================================\n",
    "print(\"\\nPART 2: 데이터 로딩 및 분할 시작...\")\n",
    "df = pd.read_csv(TABULAR_DATA_PATH)\n",
    "df['계약일자'] = pd.to_datetime(df['계약일자'])\n",
    "df = df.sort_values('계약일자').reset_index(drop=True)\n",
    "df['image_filename'] = [f'apt_image_{i}.jpg' for i in df.index]\n",
    "df['image_path'] = df['image_filename'].apply(lambda f: os.path.join(IMAGE_DIRECTORY, f))\n",
    "\n",
    "# 데이터 분할 (7:2:1 비율)\n",
    "n_total = len(df)\n",
    "train_end = int(n_total * 0.7)\n",
    "val_end = int(n_total * 0.9)\n",
    "train_df = df[:train_end].copy()\n",
    "val_df = df[train_end:val_end].copy()\n",
    "test_df = df[val_end:].copy()\n",
    "print(f\"데이터 분할 완료: Train={len(train_df)}, Validation={len(val_df)}, Test={len(test_df)}\")\n",
    "print(\"PART 2: 완료!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b03263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PART 3: 멀티모달 특징 추출 시작...\n",
      "훈련 데이터로 PCA 모델 학습...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-26 16:50:07.583325: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236/236 [==============================] - 303s 1s/step\n",
      "검증 및 테스트 데이터 변환...\n",
      "68/68 [==============================] - 87s 1s/step\n",
      "34/34 [==============================] - 44s 1s/step\n",
      "이미지 특징 추출 완료.\n",
      "472/472 [==============================] - 0s 347us/step\n",
      "135/135 [==============================] - 0s 149us/step\n",
      "68/68 [==============================] - 0s 157us/step\n",
      "정형 데이터 특징 추출 완료.\n",
      "472/472 [==============================] - 0s 164us/step\n",
      "135/135 [==============================] - 0s 165us/step\n",
      "68/68 [==============================] - 0s 176us/step\n",
      "최종 융합된 훈련 데이터 형태: (15092, 256)\n",
      "PART 3: 완료!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ===================================================================\n",
    "# PART 3: 멀티모달 특징 추출 파이프라인\n",
    "# ===================================================================\n",
    "print(\"\\nPART 3: 멀티모달 특징 추출 시작...\")\n",
    "\n",
    "# --- 3.1. 이미지 특징 추출 ---\n",
    "def extract_image_features_2048d(image_paths, batch_size=BATCH_SIZE):\n",
    "    \"\"\"ResNet50으로 고차원 특징 벡터를 추출하는 헬퍼 함수\"\"\"\n",
    "    image_input = Input(shape=(224, 224, 3), name='image_input')\n",
    "    base_cnn = ResNet50(weights='imagenet', include_top=False, pooling='avg', input_tensor=image_input)\n",
    "    base_cnn.trainable = False\n",
    "    extractor_model = Model(inputs=image_input, outputs=base_cnn.output, name='resnet50_feature_extractor')\n",
    "    \n",
    "    def image_generator(paths, b_size):\n",
    "        for i in range(0, len(paths), b_size):\n",
    "            batch_paths = paths[i:i+b_size]\n",
    "            batch_images = []\n",
    "            for p in batch_paths:\n",
    "                try:\n",
    "                    img = load_img(p, target_size=(224, 224))\n",
    "                    img_array = img_to_array(img)\n",
    "                    batch_images.append(img_array)\n",
    "                except (FileNotFoundError, IOError):\n",
    "                    batch_images.append(np.zeros((224, 224, 3)))\n",
    "            yield preprocess_input(np.array(batch_images))\n",
    "            \n",
    "    num_batches = int(np.ceil(len(image_paths) / batch_size))\n",
    "    features = extractor_model.predict(image_generator(image_paths, batch_size), steps=num_batches, verbose=1)\n",
    "    return features\n",
    "\n",
    "# 훈련 데이터로 PCA 모델 학습(fit)\n",
    "print(\"훈련 데이터로 PCA 모델 학습...\")\n",
    "train_image_features_2048d = extract_image_features_2048d(train_df['image_path'].tolist())\n",
    "pca = PCA(n_components=IMAGE_PCA_COMPONENTS)\n",
    "image_vectors = {'train': pca.fit_transform(train_image_features_2048d)}\n",
    "\n",
    "# 검증 및 테스트 데이터 변환(transform)\n",
    "print(\"검증 및 테스트 데이터 변환...\")\n",
    "val_image_features_2048d = extract_image_features_2048d(val_df['image_path'].tolist())\n",
    "image_vectors['val'] = pca.transform(val_image_features_2048d)\n",
    "test_image_features_2048d = extract_image_features_2048d(test_df['image_path'].tolist())\n",
    "image_vectors['test'] = pca.transform(test_image_features_2048d)\n",
    "print(\"이미지 특징 추출 완료.\")\n",
    "\n",
    "# --- 3.2. 정형 데이터 특징 추출 ---\n",
    "tabular_cols = [\n",
    "    '전용면적(㎡)', '층', '건축년도', '아파트 나이', 'leading_index', '건설기성액(백만원)', \n",
    "    '부동산_소비심리지수', '주택시장_소비심리지수', '강남구_변동률', '강남구_누계', \n",
    "    '토지시장_소비심리지수', '아파트_호수', '아파트_면적', 'rate'\n",
    "]\n",
    "# 훈련 데이터로 스케일러 학습(fit)\n",
    "tabular_scaler = MinMaxScaler() \n",
    "train_tabular_scaled = tabular_scaler.fit_transform(train_df[tabular_cols])\n",
    "# 검증 및 테스트 데이터 변환(transform)\n",
    "val_tabular_scaled = tabular_scaler.transform(val_df[tabular_cols])\n",
    "test_tabular_scaled = tabular_scaler.transform(test_df[tabular_cols])\n",
    "\n",
    "# MLP 특징 추출기 모델 생성\n",
    "mlp_input = Input(shape=(len(tabular_cols),), name='tabular_input')\n",
    "embedding_layer = Dense(TABULAR_MLP_COMPONENTS, activation='relu')(mlp_input)\n",
    "mlp_extractor = Model(inputs=mlp_input, outputs=embedding_layer, name='mlp_feature_extractor')\n",
    "\n",
    "# 각 데이터셋을 MLP로 변환\n",
    "tabular_vectors = {\n",
    "    'train': mlp_extractor.predict(train_tabular_scaled),\n",
    "    'val': mlp_extractor.predict(val_tabular_scaled),\n",
    "    'test': mlp_extractor.predict(test_tabular_scaled)\n",
    "}\n",
    "print(\"정형 데이터 특징 추출 완료.\")\n",
    "\n",
    "# --- 3.3. 특징 융합 ---\n",
    "combined_vectors = {s: np.concatenate([tabular_vectors[s], image_vectors[s]], axis=1) for s in ['train', 'val', 'test']}\n",
    "fusion_input_dim = combined_vectors['train'].shape[1]\n",
    "fusion_input = Input(shape=(fusion_input_dim,))\n",
    "fusion_output = Dense(FUSION_COMPONENTS, activation='relu', name='fusion_layer')(fusion_input)\n",
    "fusion_model = Model(inputs=fusion_input, outputs=fusion_output, name='fusion_model')\n",
    "X_final = {s: fusion_model.predict(combined_vectors[s]) for s in ['train', 'val', 'test']}\n",
    "print(f\"최종 융합된 훈련 데이터 형태: {X_final['train'].shape}\")\n",
    "print(\"PART 3: 완료!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30e2fdfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PART 4: 타겟 데이터 준비 및 시퀀스 생성 시작...\n",
      "최종 시퀀스 형태: X_train_seq: (15080, 12, 256)\n",
      "PART 4: 완료!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ===================================================================\n",
    "# PART 4: 타겟 데이터 준비 및 시계열 시퀀스 생성\n",
    "# ===================================================================\n",
    "print(\"\\nPART 4: 타겟 데이터 준비 및 시퀀스 생성 시작...\")\n",
    "TARGET_COL = '면적당 단가(만원)'\n",
    "\n",
    "# 로그 변환 추가 (데이터 분포를 안정화하고, 모델이 상대적 변화에 집중하도록 함)\n",
    "df[TARGET_COL] = np.log1p(df[TARGET_COL])\n",
    "\n",
    "scaler_y = MinMaxScaler()\n",
    "y_train_scaled = scaler_y.fit_transform(df.loc[:train_end-1, [TARGET_COL]])\n",
    "y_val_scaled = scaler_y.transform(df.loc[train_end:val_end-1, [TARGET_COL]])\n",
    "y_test_scaled = scaler_y.transform(df.loc[val_end:, [TARGET_COL]])\n",
    "\n",
    "def create_sequences(X_data, y_data, timesteps=TIMESTEPS):\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(len(X_data) - timesteps):\n",
    "        X_seq.append(X_data[i:(i + timesteps)])\n",
    "        y_seq.append(y_data[i + timesteps])\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "X_train_seq, y_train_seq = create_sequences(X_final['train'], y_train_scaled)\n",
    "X_val_seq, y_val_seq = create_sequences(X_final['val'], y_val_scaled)\n",
    "X_test_seq, y_test_seq = create_sequences(X_final['test'], y_test_scaled)\n",
    "print(f\"최종 시퀀스 형태: X_train_seq: {X_train_seq.shape}\")\n",
    "print(\"PART 4: 완료!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3e2f8e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PART 5: TCN 모델 학습 및 평가 시작...\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " tcn (TCN)                   (None, 32)                39200     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,289\n",
      "Trainable params: 40,289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "236/236 [==============================] - 2s 5ms/step - loss: 0.3825 - val_loss: 0.1543\n",
      "Epoch 2/50\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.1211 - val_loss: 0.1176\n",
      "Epoch 3/50\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.1116 - val_loss: 0.1199\n",
      "Epoch 4/50\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.1083 - val_loss: 0.1180\n",
      "Epoch 5/50\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.1056 - val_loss: 0.1180\n",
      "Epoch 6/50\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.1033 - val_loss: 0.1116\n",
      "Epoch 7/50\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.1010 - val_loss: 0.1093\n",
      "Epoch 8/50\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.0991 - val_loss: 0.1070\n",
      "Epoch 9/50\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.0972 - val_loss: 0.0994\n",
      "Epoch 10/50\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.0953 - val_loss: 0.1012\n",
      "Epoch 11/50\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.0936 - val_loss: 0.0999\n",
      "Epoch 12/50\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.0922 - val_loss: 0.1005\n",
      "Epoch 13/50\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.0907 - val_loss: 0.1011\n",
      "Epoch 14/50\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.0895 - val_loss: 0.0964\n",
      "Epoch 15/50\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.0883 - val_loss: 0.0983\n",
      "Epoch 16/50\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.0870 - val_loss: 0.0939\n",
      "Epoch 17/50\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.0861 - val_loss: 0.0924\n",
      "Epoch 18/50\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.0849 - val_loss: 0.0940\n",
      "Epoch 19/50\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.0842 - val_loss: 0.0909\n",
      "Epoch 20/50\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.0832 - val_loss: 0.0842\n",
      "Epoch 21/50\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.0827 - val_loss: 0.0885\n",
      "Epoch 22/50\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.0819 - val_loss: 0.0885\n",
      "Epoch 23/50\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.0815 - val_loss: 0.0861\n",
      "Epoch 24/50\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.0805 - val_loss: 0.0877\n",
      "Epoch 25/50\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.0806 - val_loss: 0.0878\n",
      "Epoch 26/50\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.0796 - val_loss: 0.0893\n",
      "Epoch 27/50\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.0798 - val_loss: 0.0913\n",
      "Epoch 28/50\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.0792 - val_loss: 0.0868\n",
      "Epoch 29/50\n",
      "236/236 [==============================] - 1s 6ms/step - loss: 0.0786 - val_loss: 0.0878\n",
      "Epoch 30/50\n",
      "236/236 [==============================] - 1s 5ms/step - loss: 0.0786 - val_loss: 0.0980\n",
      "68/68 [==============================] - 0s 743us/step\n",
      "\n",
      "--- 테스트셋 최종 성능 MAE: 0.04 만원 ---\n",
      "PART 5: 완료!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ===================================================================\n",
    "# PART 5: TCN 모델 학습 및 평가\n",
    "# ===================================================================\n",
    "print(\"\\nPART 5: TCN 모델 학습 및 평가 시작...\")\n",
    "tcn_input_shape = (TIMESTEPS, FUSION_COMPONENTS)\n",
    "# 과적합 방지를 위해 모델 구조 단순화 및 규제 추가\n",
    "tcn_model = tf.keras.models.Sequential([\n",
    "    TCN(input_shape=tcn_input_shape, nb_filters=32, kernel_size=2, dilations=[1, 2, 4, 8],\n",
    "        use_skip_connections=True, dropout_rate=0.2, return_sequences=False),\n",
    "    Dense(32, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "    Dense(1)\n",
    "])\n",
    "tcn_model.compile(optimizer='adam', loss='mae')\n",
    "tcn_model.summary()\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "history = tcn_model.fit(\n",
    "    X_train_seq, y_train_seq,\n",
    "    validation_data=(X_val_seq, y_val_seq),\n",
    "    epochs=EPOCHS, batch_size=BATCH_SIZE,\n",
    "    callbacks=[early_stopping], verbose=1\n",
    ")\n",
    "\n",
    "# 모델 평가\n",
    "y_pred_scaled = tcn_model.predict(X_test_seq)\n",
    "y_pred_original_log = scaler_y.inverse_transform(y_pred_scaled)\n",
    "y_test_original_log = scaler_y.inverse_transform(y_test_seq)\n",
    "# 로그 역변환\n",
    "y_pred_original = np.expm1(y_pred_original_log)\n",
    "y_test_original = np.expm1(y_test_original_log)\n",
    "mae = mean_absolute_error(y_test_original, y_pred_original)\n",
    "print(f\"\\n--- 테스트셋 최종 성능 MAE: {mae:.2f} 만원 ---\")\n",
    "print(\"PART 5: 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992327fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PART 6: 시나리오 기반 미래 예측 시작...\n",
      "수동으로 설정된 시나리오 변동률:\n",
      "               낙관적  중립적  보수적\n",
      "leading_index 1.00 1.00 1.00\n",
      "건설기성액(백만원)    1.00 1.00 1.00\n",
      "부동산_소비심리지수    1.00 1.00 1.00\n",
      "주택시장_소비심리지수   1.00 1.00 1.00\n",
      "강남구_변동률       1.00 1.00 1.00\n",
      "강남구_누계        1.00 1.00 1.00\n",
      "토지시장_소비심리지수   1.00 1.00 1.00\n",
      "rate          1.00 1.00 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "미래 예측 중: 100%|██████████| 12/12 [00:01<00:00,  7.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PART 6: 완료!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ===================================================================\n",
    "# PART 6: 시나리오 기반 미래 예측\n",
    "# ===================================================================\n",
    "print(\"\\nPART 6: 시나리오 기반 미래 예측 시작...\")\n",
    "\n",
    "# --- 6.1. 시나리오 변동률 수동 정의 ---\n",
    "economic_indicators = [\n",
    "    'leading_index', '건설기성액(백만원)', '부동산_소비심리지수', '주택시장_소비심리지수',\n",
    "    '강남구_변동률', '강남구_누계', '토지시장_소비심리지수', 'rate'\n",
    "]\n",
    "scenarios = {\n",
    "    '낙관적': {'leading_index': 1.002, '건설기성액(백만원)': 1.001, '부동산_소비심리지수': 1.003, '주택시장_소비심리지수': 1.003, '강남구_변동률': 1.002, '강남구_누계': 1.001, '토지시장_소비심리지수': 1.002, 'rate': 0.999},\n",
    "    '중립적': {'leading_index': 1.0, '건설기성액(백만원)': 1.0, '부동산_소비심리지수': 1.0, '주택시장_소비심리지수': 1.0, '강남구_변동률': 1.0, '강남구_누계': 1.0, '토지시장_소비심리지수': 1.0, 'rate': 1.0},\n",
    "    '보수적': {'leading_index': 0.998, '건설기성액(백만원)': 0.999, '부동산_소비심리지수': 0.997, '주택시장_소비심리지수': 0.997, '강남구_변동률': 0.998, '강남구_누계': 0.999, '토지시장_소비심리지수': 0.998, 'rate': 1.001}\n",
    "}\n",
    "print(\"수동으로 설정된 시나리오 변동률:\")\n",
    "print(pd.DataFrame(scenarios).round(4))\n",
    "\n",
    "# --- 6.2. 재귀적 예측 실행  ---\n",
    "initial_raw_df = df.tail(TIMESTEPS).copy()\n",
    "initial_final_features = np.vstack([X_final['val'], X_final['test']])[-TIMESTEPS:]\n",
    "\n",
    "scenario_predictions_log = {name: [] for name in scenarios.keys()}\n",
    "current_raw_dfs = {name: initial_raw_df.copy() for name in scenarios.keys()}\n",
    "current_final_features = {name: initial_final_features.copy() for name in scenarios.keys()}\n",
    "\n",
    "for i in tqdm(range(FORECAST_HORIZON), desc=\"미래 예측 중\"):\n",
    "    for name, params in scenarios.items():\n",
    "        # (1) 현재 시퀀스(최종 특징 벡터)를 바로 모델 입력으로 사용\n",
    "        input_sequence = np.reshape(current_final_features[name], (1, TIMESTEPS, FUSION_COMPONENTS))\n",
    "        \n",
    "        # (2) 모델로 1개월 후 가격 예측 (로그 스케일)\n",
    "        pred_scaled = tcn_model.predict(input_sequence, verbose=0)\n",
    "        pred_log = scaler_y.inverse_transform(pred_scaled)[0][0]\n",
    "        scenario_predictions_log[name].append(pred_log)\n",
    "        \n",
    "        # (3) 다음 예측에 사용할 '가상의 미래 데이터' 한 줄 생성 (Raw DF 기준)\n",
    "        next_raw_row = current_raw_dfs[name].iloc[-1:].copy()\n",
    "        next_raw_row['계약일자'] += pd.DateOffset(months=1)\n",
    "        for indicator in economic_indicators:\n",
    "            next_raw_row[indicator] *= params[indicator]\n",
    "        next_raw_row[TARGET_COL] = pred_log\n",
    "        \n",
    "        # (4) '가상의 미래 데이터' 한 줄만 새로 특징 추출\n",
    "        next_tabular_scaled = tabular_scaler.transform(next_raw_row[tabular_cols])\n",
    "        next_tabular_feature = mlp_extractor.predict(next_tabular_scaled, verbose=0)\n",
    "        \n",
    "        # 이미지 특징은 마지막 값을 그대로 재사용\n",
    "        last_image_feature = image_vectors['test'][-1].reshape(1, -1)\n",
    "        \n",
    "        next_combined_feature = np.concatenate([next_tabular_feature, last_image_feature], axis=1)\n",
    "        next_final_feature = fusion_model.predict(next_combined_feature, verbose=0)\n",
    "        \n",
    "        # (5) 특징 벡터 시퀀스 업데이트\n",
    "        updated_features = np.vstack([current_final_features[name][1:], next_final_feature])\n",
    "        current_final_features[name] = updated_features\n",
    "        \n",
    "        # (6) Raw DF 시퀀스도 다음 루프를 위해 업데이트\n",
    "        updated_df = pd.concat([current_raw_dfs[name].iloc[1:], next_raw_row], ignore_index=True)\n",
    "        current_raw_dfs[name] = updated_df\n",
    "\n",
    "print(\"PART 6: 완료!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55701865",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ===================================================================\n",
    "# PART 7: 최종 결과 출력\n",
    "# ===================================================================\n",
    "print(\"\\nPART 7: 최종 결과 출력...\")\n",
    "future_dates = pd.date_range(start=df['계약일자'].max() + pd.DateOffset(months=1), periods=FORECAST_HORIZON, freq='MS')\n",
    "results_df_log = pd.DataFrame(scenario_predictions_log, index=future_dates)\n",
    "results_df = np.expm1(results_df_log) # 로그 역변환\n",
    "results_df = results_df[['낙관적', '중립적', '보수적']]\n",
    "results_df.columns = ['낙관적 예측(만원)', '중립적 예측(만원)', '보수적 예측(만원)']\n",
    "results_df.index.name = '예측 시점'\n",
    "\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "print(\"\\n\" + \"=\"*75)\n",
    "print(\"                  시나리오 기반 미래 12개월 매매 가격 예측 (실제 단위)\")\n",
    "print(\"=\"*75)\n",
    "print(results_df)\n",
    "print(\"=\"*75)\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.plot(results_df['낙관적 예측(만원)'], 'go-', label='낙관적 시나리오')\n",
    "plt.plot(results_df['중립적 예측(만원)'], 'bo-', label='중립적 시나리오')\n",
    "plt.plot(results_df['보수적 예측(만원)'], 'ro-', label='보수적 시나리오')\n",
    "plt.xlabel('예측 시점', fontsize=14)\n",
    "plt.ylabel('면적당 단가 (만원)', fontsize=14)\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81c3593",
   "metadata": {},
   "source": [
    "![apt](/Users/kim-youngho/git/APT-TCN/images/final_result.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b84e10",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "apt_sale",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
